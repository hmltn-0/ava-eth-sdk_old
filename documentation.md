1. What is "EigenLayer"?
2. What kind of "aggregation" is occurring? Is it the aggregation of operator transmissions, as a form of network broadcasting?
3. Is grpc a protocol?
4. Why does Eignlayer off "telemetry monitoring"? Of what, the blockchain? How so?


- Email: developers@avaprotocol.org
- Twitter: https://x.com/ava_protocol
- Telegram: https://t.me/ava_protocol
- Discord: https://discord.gg/7W9UDvsbwh
- LinkedIn: https://www.linkedin.com/company/avaprotocol
- Github: https://github.com/AvaProtocol/

- Operstors request task data from aggregators
- Operators perform condition executions
- to check whether a task can be triggered
    - For example, what kinds of conditions?

- How do I just start using Ava AVS? With protobuf, or grpc?


- The result is sent back to aggregator
- Aggregators handle book-keeping
- for off-chain storag
- and on-chain storage


- running an operator does not require
- topping up
- the operator ECDSA
- or alias key.

What is "topping up an ECDSA or alias key"?

Can individuals run either operators or aggregators with the Ava Protocol / AVS?


- An operator that is connected to an Ava Protocol aggregator
- can also check their operator on our telemetry dashboard:
- Holesky is a test network:
- https://aggregator-holesky.avaprotocol.org/telemetry
- This is the main network:
- https://aggregator.avaprotocol.org/telemetry

- Ava Protocol automates processes on Ethereum
- Ava Protocol is a hub for cross-chain automation,

How is it cross-chain if it only automates Ethereum?


- enabling multi-chain apps to schedule and automate
- any EVM-based transaction or smart contract function.

It delivers
-  trustless
-  automation
-   by dedicating
-   block space
-   and optimizing gas usage
-   to store
- and execute
- transactions
- across connected blockchains.
- This automation engine
- combines off-chain
- data streams
- and event-driven
- execution
- to trigger
- transactions
- on Ava Protocol
- and connected blockchains —
- all without handling tokens
- or private keys.
- Ava Protocol
- enables fluid user experiences
- like scheduled
- and recurring payments,
- stable-cost averaging,
- stop-loss orders,
- and auto-compounding rewards
- for staking,
- liquidity pools,
- and money market deposits.
- Ava Protocol
- provides
- automation infrastructure
- for decentralized applications
- (dapps)
- to manage
- single or recurring transactions
- using simple
- "if this, then that"
- logic.
- Modular
- and Composable Technical Stack
- Ava Protocol’s technical stack
- offers a suite
- of robust,
- customizable,
- and interoperable tools
- designed to streamline
- and secure the development
- and management of
- decentralized applications.
- The Studio
- is a highly customizable interface
- for creating,
- designing,
- and managing
- automated trading strategies
- and asset management
- workflows.
- Customization
- and Flexibility:
- The Studio
- provides a drag-and-drop interface
- that allows users
-  to build and adjust
-  trading strategies
-  without coding.
-  This flexibility
-  lets users
-  tailor strategies
-  to fit
-  specific needs
-  and market conditions.
- Integration
- with APIs:
- It integrates
- seamlessly
- with various financial data APIs,
- providing access
-  to real-time
-  and historical market data,
- along with
- other essential metrics
- necessary for
- informed decision-making.
- Backtesting
- and Simulation:
- The Studio offers
- robust backtesting tools
- that enable users
- to test strategies
- against historical data
- and evaluate their effectiveness
- before live deployment.
- Automation
- and Scheduling:
- Users can automate their strategies
- to execute trades
- based on specific times
- or market conditions,
- improving efficiency
- and responsiveness.
- Security
- and Compliance:
- The Studio
- adheres
- to stringent
- security protocols
- to protect user data
- and transactions
- while supporting
- compliance with
- relevant financial regulations
- and standards.
- Modular SDK
- The Ava Protocol SDK
- (Software Development Kit)
- provides modular
- and easy-to-use tools
- for integrating
- seamless and secure
- private transactions
- into dapps
- and services.
- Technical Details
- Development Tools:
- The SDK
- includes libraries,
- sample code,
- and documentation
- to help developers
- integrate advanced features
- with minimal effort.
- It supports
- multiple programming languages
- and platforms.
- Security and Privacy:
- Built with a focus on security,
- the SDK ensures
- that all transactions
- and sensitive data
- are encrypted
- and secure.
- Interoperability:
- The SDK
- is designed
- to be modular
- and interoperable,
- enabling developers
- to build applications
- that can interact
- with different
- blockchain networks
- and systems.
- Scalability:
- It supports
- scalable solutions,
- allowing applications
- to handle
- large transaction volumes
- without compromising
- performance.
- The SDK
- includes optimization tools
- to ensure efficient use
- of resources.
- Community and Support:
- Developers have access to
- a community of users
- and extensive
- support resources,
- including forums,
- FAQs,
- and direct support channels,
- making it easy
- to find help
- and share knowledge.
- EigenLayer AVS
- Ava Protocol
- is an Actively Validated Service
- (AVS)
- on EigenLayer,
- an innovative
- restaking protocol
- that leverages
- Ethereum's
- pooled cryptoeconomic security.
- Why We Chose EigenLayer
- Network Security:
-  EigenLayer utilizes
-  restaked ETH
-  to validate
-  decentralized services,
-  ensuring that the network
-  is secure and resistant
-  to attacks.
- Event-Driven Architecture:
-  Event-driven activation
-  is a key AVS use case
-  supported by EigenLayer,
-  triggering actions
-  for real-time applications
-  based on specific events.
- Off-chain computation
- and storage:
- The off-chain resources
- of EigenLayer operators
- allow Ava Protocol
- to tailor data structures
- for efficient,
-  event-driven activation,
-  providing scalability
-  for complex computations
-  and data management.
- Scalability and Efficiency:
- EigenLayer is designed
- to be
- highly scalable,
- capable of handling
- high volumes of transactions
- and events
- without performance issues.
- Inclusion Guarantees:
- The network ensures
- that all valid transactions
- and events
- are included in the blockchain,
-  maintaining integrity
-  and reliability.
- Cross-Chain interoperability:
- With connectivity facilitated
- by different AVSs
- in the EigenLayer ecosystem,
- such as oracles and bridges,
- Ava Protocol
- can validate
- Layer-2s and
- EVM-compatible chains,
-  offering automation services
-  to a range of dapps
-   and services.
-   EigenLayer jumpstarts
-   the launch of
-   Ava Protocol's
-   super-transactions service
-   on Ethereum,
-   rapidly providing
-   a secure network
-   and proof-of-stake
-   consensus method
-   to guarantee
-   the accuracy
-   of automations.
-   How Ava Protocol Is Different
- No more wrapped assets：
- Assets are supported
- by the chain directly,
- eliminating the need
- for them to be locked
- in a single smart contract.
- Eliminate off-chain servers:
- Repetitive transactions
- can be triggered
- by on-chain
- event modules.
- No private key custody:
- Once set up,
- on-chain transactions
- can be triggered
- automatically
- without further input.
- Chain-level security:
- Unlike EVM smart contracts,
- core utility functions
- are secured by the network.
- Execution guarantees:
- Users can be assured
- that their events
- will reliably execute
- based on specific conditions.
- Ava Protocol Ecosystem
- Ava Protocol
- has integrated
- with a diverse range
- of dapps
- and services
- that showcase
- the versatility
- and potential
- of our automation solutions.
- Web3Go:
- Enabling data analytics
- and insights
- for blockchain networks,
- helping developers
- make informed decisions.
- Bagpipes:
- A no-code DeFi automation tool
-  that allows users
-  to create
-  custom cross-chain workflows
-  with ease.
- ACE:
-  Providing advanced tools
-  for asset management
-  and trading strategy
-  automation.
- YieldBay:
- Offering auto-compounding
- solutions
- to maximize returns
- for liquidity pool
- participants.
- Mangata X:
- Facilitating cross-chain
- trading
- with minimal slippage
- and high efficiency.
- YieldBoot:
- Automating yield farming
- strategies
- to optimize returns
- across multiple DeFi platforms.
- These dapps leverage
- Ava Protocol’s
- advanced features —
- such as seamless integration
- with off-chain data,
- event-driven automation,
-  and secure transaction
-  execution —
-   to deliver
-   exceptional user experiences
-   and drive the next wave
-   of blockchain innovation.
- Optional steps
- to enhance
- the security
- of your EigenLayer operator,
-  including SSH configuration,
-  firewall setup,
-  and more.
-  The goal of this guide
-  is to walk you through
-  steps you can take
-   to secure your node
-   against malicious actors.
-   Whether you're running
-   a local server at home
-   or a VPS server /
-   virtual machine
-   on the cloud,
-   the tips here
-   will help you harden
-   your node against
-   outside attack
-   and help protect
-   it during its lifespan.
-   This section will describe
-   both essential actions,
-    which you must take,
-    and nice-to-have actions,
-  which are helpful
-   but not required.
-   Note:This guide
-   is meant to be an
-   introduction to
-   some of the things
-   you can do
-   to harden your
-   node machine.
-    If you are comfortable
-    with the command-line
-    terminal
-    and want to go even further
-    in protecting your node,
-    take a look at the
-    popular
-    imthenachoman/
-    How-To-Secure-A-Linux-Server
-    guide.
-    Assumptions in This Guide
-    This guide assumes
-    your node runs
-    Ubuntu 20.04 LTS
-  Theconcepts will carry over
-  to other systems
-  but the example commands
-  may not.
-  As with all of the commands
-  in this guide,
-  we assume that
-  you are connecting remotely
-  to your node's command terminal
-  using ssh
-  If you need a refresher
-  on how to use ssh
-   take a look at the
-   Intro to Secure Shell guide
-    first.
-    Essential:
-    Keep your Operator
-    Machine Secure
-    Warning: If you use your node
-    locally
-  (by physically logging into it
-  with a keyboard
-  and monitor
-  directly attached to it),
-   then this section
-   is not relevant to you -
-   you can skip it.
-   Most operators
-   interact with their node
-   remotely by connecting to
-   its terminal
-   from another computer
-   using ssh
-   The machine you connect to
-   (in this case,
-   your node machine)
-    is called the server.
- The machine you connect from
- (such as your laptop,
- desktop, or even your phone)
- is the client.
- One of the most important
- things you can do to
- secure your node
- is to keep your
- operator machine secure.
- If your operator machine
- is compromised
- and you use it to log into
- your node,
- then most of the security
- settings you apply to the
- node can be bypassed.
- For example:
- if you use a laptop
- as an SSH client,
- and it has a keylogger
- installed,
- then any secret things
- you type on the node
- (such as your password
- or recovery mnemonic)
- when connected via SSH
- will be stolen.
- There is no definitive guide
- to keeping your
- operator machine secure,
- but being aware
- that it is a factor
- in your security
- is a good first step.
- Make sure that your operator
- machine
- is as secure as it can be.
- Here are a few tips:
- Don't use your operator
- machine for risky activities
- (such as visiting
- untrustworthy websites
- or installing unnecessary
- programs)
- Keep your operator machine
- updated
- with the latest security
- patches
- If possible,
- use a malware and
- antivirus protection program
- for your Operating System
- For maximum security,
-  you may want to use
-  a dedicated machine
-  as your SSH client,
-  though this may not be
-  practical for you.
-  Essential:
-   Secure your SSH Access
-   Warning:
-    If you use your node
-    locally
-  (by physically logging
-  into it with a keyboard
-  and monitor
-  directly attached to it),
-  then this section
-  is not relevant to you -
-  you can skip it.
-  Whether you run your node
-   at home or use a VPS in a
-   remote datacenter,
-   it is likely
-   that you access it
-   through SSH,
-    or that SSH
-    is enabled
-    even if you do not use it.
-    SSH connections
-    are based on
-    secure cryptography,
-    but as with any
-    secure system,
-    the real security
-    comes from using it
-    correctly.
-    There are two main things
-    to do for your SSH settings:
-    use an SSH key to
-    log in remotely
-    instead of a username
-    and password
- Disable password-based
- authentication entirely,
- so SSH keys are
- the only remote
- login option
- As you are probably
- familiar with now,
- the default way
- to log into your node
- via SSH
- is with a username
- and password.
- The downside of this
- is that your password
- is typically something
- rather "short" and
- susceptible to brute-force
- attacks.
- Luckily, there is an
- alternative way to
- log in via SSH:
- an SSH key pair.
- SSH key pairs
- work similarly
- to blockchain wallets;
- they come with
- a public part
-  (such as your wallet
-  address)
-  and a private part
-  (the private key
-  for your wallet address):
- You provide the public part
-  to your node.
-  This way,
-  the node knows
-  you're allowed to
-  connect to it,
-  and it knows
-  that it's really you
-  trying to connect.
- You keep the private part
-  to yourself
-  on your operator machine
-   This way, you
-   (and only you)
-   can connect to your node.
- You can (and should!)
- protect the private part
- with a password,
- so someone who steals your
- key can't use it.
- From a computer's perspective,
- the private key
- is exponentially harder
- to crack than a password is.
-  This mitigates the risk
-  of a brute-force attack
-  against your node.
-  Tip: If you'd like to learn
-   more about SSH key pairs
-   before creating your own,
-    take a look at these links:
- https://canvas.cse.taylor.edu/courses/27/pages/ssh-key-tutorial
- https://www.ssh.com/academy/ssh/host-key
- Creating an SSH Key Pair
- Let's start by creating
- a new SSH key pair
- on your operator machine.
-  There are many varieties
-  of key out there,
-  but we're going to use
-  a key type called ed25519
-  which provides excellent
-  security.
-  Run the following command
-  on your operator machine (
-  i.e., you should not run
-  this while already SSH'd
-  into your node machine -
-  if you are,
-  exit out of SSH first):
-  ssh-keygen -t
-  ed25519 -C
-  "your_email@example.com"
-  You will see the following:
-  Generating public/private
-  ed25519 key pair.
-  Enter file in which
-  to save the key
-  (/home/username/
-  .ssh/id_ed25519):
-  This asks you
-  where you would like
-  to save your private key
-  file.
-  SSH is compatible
-  with the provided default
-  and will automatically
-  use it for you
-  if you select it.
-  However, you have the
-  option of changing it
-  to something else
-  if you wish.
-  Note:
-  The path /home/username/
-  .ssh/id_ed25519
-  is just an example,
-  assuming your username
-  is username.
-  You likely have
-  a different username.
-  Whenever you see
-  a path like the above
-  in this guide,
-  replace it with
-  whatever path
-  your system actually prints
-  with your actual username.
-  If you are comfortable
-  with the default setting,
-  simply press Enter.
-  Otherwise,
-  type your desired location
-  for the key.
-   It must be an absolute path
-   (e.g. /home/username/
-   .ssh/eigenlayer_key
-   on Linux,
-   or /Users/username/
-   .ssh/eigenlayer_key
-   on OSX).
-   Press Enter
-   when you’re done.
-   After pressing Enter
-    you will see:
-    Enter passphrase
-  (empty for no passphrase):
-  This will become
-  the password
-  for the private key itself.
-  Whenever you use the key
-  to connect to your node,
-   you will need to enter
-   this password first.
-   Warning: You should not leave
-   this blank -
-   otherwise,
-   anyone with the SSH key
-   file will be able to use it!
-    Pick a good password
-    that you (and only you)
-    will know.
-    Also, don't forget your password
-  - there is no way to recover
   - this password
   - if you lose it.
   - Once you finish typing the
- password,
- press Enter.
- It will ask you
- to retype it
- for confirmation.
- After that,
- you will see something
- like the following output:
- Your identification
- has been saved
- in /home/username/
- .ssh/id_ed25519
- Your public key
- has been saved
- in /home/username/
- .ssh/id_ed25519.pub
- The key fingerprint is:
- SHA256:CASbPZETiQ83lLhpUO2aoT05TxMVLwqiWtdsRtoPt4s your_email@example.com
- The key's randomart image
- is:
+--[ED25519 256]--+
| .o*==.. |
|. +=O... |
|..+B++o . |
|..=.+X o |
|.+.=+.O S |
|o.B.oo + . |
|. = . o |
| . . . |
| E . |
+----[SHA256]-----+
- The first line states
- the location of the private
- key,
- which is called id_ed25519
- by default
-  (notice that it does not
-  have a file extension).
-  Ubuntu will load this key
-  for you automatically
-  when you use ssh
-  if this private key file
-  is in the default location.
-  The second line states the location of the public key, which is called id_ed25519.pub
by default.
We'll need the public key for the next step.
Note: Ubuntu should load this new key automatically. However, some systems (such as macOS machines) will not load it automatically - you will have to tell it to do this with the following command on your operator machine:
ssh-add $HOME/.ssh/id_ed25519
Note that this is the path of the private key that we generated in the previous step, not the public key. Replace the path with whatever your system printed in that previous step.
If you get an error saying that the ssh-agent
is not running, start it by running the following command on your operator machine:
eval $(ssh-agent)
If you don't want to type these two commands every time you open the terminal, you can create a shortcut for adding your key by adding an alias
to your ~/.bashrc
file.
Open the file using the text editor:
nano ~/.bashrc
Add this line to the end (assuming you used the default path for the private key - update as necessary):
alias loadkey='ssh-add $HOME/.ssh/id_ed25519'
Save and exit with Ctrl+O
and Enter
, then Ctrl+X
.
Next, close and open your terminal for the changes to take effect.
You can now type loadkey
on your operator machine to load the key.
Adding the Public Key to your Node
Once you have your SSH key pair, you can now add the public key to your node.
This will let you connect to it over ssh
using the private key you just generated, instead of your username and password.
Using ssh-copy-id
Note: if your operator machine is running Windows, ssh-copy-id
is not yet available.
Please follow the instructions in the "Manually Adding the Key" tab.
Run the following command on your operator machine:
ssh-copy-id -i $HOME/.ssh/id_ed25519.pub username@node.ip.address
For example, if my username on the node was staker
and my node's IP address was 192.168.1.10
, I would run the following command:
ssh-copy-id -i $HOME/.ssh/id_ed25519.pub staker@192.168.1.10
You will see some messages like the following:
/usr/bin/ssh-copy-id: INFO: Source of key(s) to be installed: "/home/username/.ssh/id_ed25519.pub"
/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed
/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys
This tells you that it's trying to log in with your key first to make sure it isn't already there. Once it fails logging in, it knows that it's OK to add the new public key to the node machine.
It will then prompt you for the password of the user on your node machine. (Note that this is not the password of the SSH key!)
Enter your user's password, and you will see the following output:
Number of key(s) added: 1
Now try logging into the machine with: "ssh 'username@node.ip.address'"
and check to make sure that only the key(s) you wanted were added.
That means it worked!
Next, use ssh
to connect to your node like you normally would (using your node's username and password).
Once you're connected to your node, run the following commands:
mkdir -p ~/.ssh
nano ~/.ssh/authorized_keys
The second command will open a text editor for the file used to store all of the public keys that your node's user account trusts.
In this file, paste the public key that you retrieved a few steps ago using the cat
command (the whole line starting with ssh-ed25519
).
When it's in, save the file with Ctrl+O
and Enter
, then press Ctrl+X
to exit.
Now, exit ssh
by running the exit
command so you return back to your local operator machine's terminal.
You should now be able to ssh
into the node like you normally would, but now you won't have to type the password of the user account.
Instead, you will have to type the password of your SSH private key. Depending on your system settings, you may only have to do this once per restart, or you may have to do it every time you use the key to connect to your node.
Disable Login-via-Password
Even though you have an SSH key pair set up, your node will still allow other machines to try to log in using the username and password method. This defeats the entire purpose of using SSH keys in the first place, so the next step is to disable those.
Note: You are about to modify the SSH server's configuration. All of your existing SSH sessions will be preserved. However, if you make a mistake, then it's possible that you will not be able to create new SSH sessions anymore and effectively lock yourself out of the machine.
To prevent this, we strongly recommend that you create 2 SSH sessions for the next steps - one for editing things and testing, and one as a backup so you can revert any breaking changes.
Start by logging into your machine using ssh
as usual:
ssh user@your.node.ip.address
As a reminder, you should do this twice on two separate terminals so you have a backup session just in case. You can ignore the backup session for now - we'll tell you when you need it. Run the following commands only in the first session.
Open the configuration file for the SSH server:
sudo nano /etc/ssh/sshd_config
As with all commands that start with sudo
, this will prompt you for your user account's password.
This is a large file, so you'll have to navigate through it using the arrow keys on your keyboard or Page Up
/ Page Down
.
Make the following changes:
- Uncomment
#AuthorizedKeysFile
if it is commented (by removing the#
in front of it) - Change
KbdInteractiveAuthentication yes
toKbdInteractiveAuthentication no
and uncomment (by removing the#
in front of it) - note that older versions of SSH call this optionChallengeResponseAuthentication
instead ofKbdInteractiveAuthentication
- Change
PasswordAuthentication yes
toPasswordAuthentication no
and uncomment (by removing the#
in front of it) - Change
PermitRootLogin yes
toPermitRootLogin prohibit-password
unless it's already set to that and has a#
in front of it
Once you're done, save with Ctrl+O
and Enter
, then exit with Ctrl+X
.
Finally, run sudo sshd -T | grep -i passwordauthentication
and make sure that it prints passwordauthentication no
.
If it does not, you may need to run sudo nano /etc/ssh/sshd_config.d/50-cloud-init.conf
and set PasswordAuthentication yes
to PasswordAuthentication no
in that file as well.
Save and exit as before, with Ctrl+O
and Enter
, then Ctrl+X
Next, restart the SSH server so it picks up the new settings:
sudo systemctl restart ssh.service
After this, logging into SSH via a username and password should be disabled.
Warning: At this point, you should exit the SSH session and try to SSH back in. If you are able to do so successfully, then your SSH configuration is still valid!
If you are not able to get back in, then something has gone wrong with your configuration. Use the backup SSH session you created at the start of this section to modify the /etc/ssh/sshd_config file.
Try to find the mistake or undo your changes, then restart the SSH server using sudo systemctl restart sshd
.
Once it’s been restarted, try connecting with SSH again on your “other” terminal. Keep doing this until you have it working again and are able to successfully connect.
(Optional) Enable Two-Factor Authentication
Two-factor authentication involves requiring a second security measure in addition to your password or SSH key, usually on a separate device from your primary one.
For example, you may be familiar with logging into a website such as a crypto exchange using both a password and a Google Authenticator code (or an SMS code). This two-step process is an example of two-factor authentication.
SSH can also be configured to require a Google Authenticator code, which means that an attacker that somehow compromised your SSH key and its passphrase would still need the device with the authenticator app on it (presumably your phone). This adds an extra layer of security to your system.
Warning: We strongly recommend that you open a second terminal with an SSH connection to your node, just in case you misconfigure something. This way, you will have a backup that is still connected in case you lock yourself out, so you can easily undo your mistakes.
If you do manage to lock yourself out, you will need to physically access your node via its local monitor and keyboard to log in and repair the misconfiguration.
Start by installing Google Authenticator (or a compatible equivalent) on your phone if you don't already have it. For Android users, consider andOTP which is an open-source alternative that supports password locking and convenient backups.
Next, install the Google Authenticator module on your node with this command:
sudo apt install -y libpam-google-authenticator
Now tell the PAM
(pluggable authentication modules) to use this module.
First, open the config file:
sudo nano /etc/pam.d/sshd
Find @include common-auth
(it should be at the top) and comment it out by adding a #
in front of it, so it looks like this:
# Standard Un*x authentication.
#@include common-auth
Next, add these lines to the top of the file:
# Enable Google Authenticator
auth required pam_google_authenticator.so
Then save and exit the file with Ctrl+O
, Enter
, and Ctrl+X
.
Now that PAM
knows to use Google Authenticator, the next step is to tell sshd
to use PAM
.
Open the sshd
config file:
sudo nano /etc/ssh/sshd_config
Now change the line KbdInteractiveAuthentication no
to KbdInteractiveAuthentication yes
so it looks like this:
# Change to yes to enable challenge-response passwords (beware issues with
# some PAM modules and threads)
KbdInteractiveAuthentication yes
(Older versions of SSH call this option ChallengeResponseAuthentication
instead of KbdInteractiveAuthentication
.)
Add the following line to the bottom of the file, which indicates to sshd
that it needs both an SSH key and the Google Authenticator code:
AuthenticationMethods publickey,keyboard-interactive:pam
Then save and exit the file with Ctrl+O
, Enter
, and Ctrl+X
.
Now that sshd
is set up, we need to create our 2FA codes.
In your terminal, run:
google-authenticator
First, it will ask you about time-based tokens.
Say y
to this question:
Do you want authentication tokens to be time-based: y
You will now see a big QR code on your screen; scan it with your Google Authenticator app to add it. You will also see your secret and a few backup codes looking like this:
Your new secret key is: IRG2TALMR5U2LK5VQ5AQIG3HA4
Your verification code is 282436
Your emergency scratch codes are:
29778030
86888537
50553659
41403052
82649596
Warning: Record the emergency scratch codes somewhere safe in case you need to log into the machine but don't have your 2FA app handy. Without the app, you will no longer be able to SSH into the machine!
Finally, it will ask you for some more parameters; the recommended defaults are as follows:
Do you want me to update your "/<username>/.google_authenticator" file: y
Do you want to disallow multiple uses of the same authentication token: y
By default... < long story about time skew > ... Do you want to do so: n
Do you want to enable rate-limiting: y
Once you're done, restart sshd
so it grabs the new settings:
sudo systemctl restart sshd
When you try to SSH into your server with your SSH keys, you should now also be asked for a 2FA verification code, but not for a password.
Essential: Enable Automatic Security Updates
Operating System vendors routinely publish updates and security fixes, so it is important that you keep your system up to date with the latest patches. The easiest way to do this is to enable automatic updates.
Run the following commands on your node machine:
sudo apt update
sudo apt install -y unattended-upgrades update-notifier-common
You can change the auto-update settings by editing /etc/apt/apt.conf.d/20auto-upgrades
:
sudo nano /etc/apt/apt.conf.d/20auto-upgrades
This is an example of reasonable auto-update settings:
APT::Periodic::Update-Package-Lists "1";
APT::Periodic::Unattended-Upgrade "1";
APT::Periodic::AutocleanInterval "7";
Unattended-Upgrade::Remove-Unused-Dependencies "true";
Unattended-Upgrade::Remove-New-Unused-Dependencies "true";
# This is the most important choice: auto-reboot.
Unattended-Upgrade::Automatic-Reboot "true";
Unattended-Upgrade::Automatic-Reboot-Time "02:00";
When you are done adding your changes, save with Ctrl+O
and Enter
, then exit with Ctrl+X
.
After, make sure to load the new settings:
sudo systemctl restart unattended-upgrades
Essential: Enable a Firewall
In general, your machine should only accept network traffic on ports that your Execution client, Consensus client, and Smartnode stack use. To enforce that and prevent any unexpected or undesirable traffic, we can install a firewall on the node.
Note: If you selected a different execution/consensus client port during the Operator setup, you need to edit the ports below to reflect your settings.
Ubuntu comes with ufw
installed by default (the uncomplicated fire wall), which is a convenient utility for managing your node's firewall settings.
The following commands will set ufw
up with a good default configuration for your Smartnode.
Run these on your node machine.
Disable connections unless they're explicitly allowed by later rules:
sudo ufw default deny incoming comment 'Deny all incoming traffic'
Allow SSH:
sudo ufw allow "22/tcp" comment 'Allow SSH'
Open node ports
For Ethereum
sudo ufw allow 9190/tcp comment 'AP Operator Metric Port'
sudo ufw allow 9191/tcp comment 'AP Operator Node API Port'
For Holesky
sudo ufw allow 9290/tcp comment 'AP Operator Metric Port'
sudo ufw allow 9291/tcp comment 'AP Operator Node API Port'
If you had customize the port either in your docker-compose.yml or in your
.env
, please adjust accordingly.
Finally, enable ufw
:
sudo ufw enable
Note:
iptables
experts might note that Docker bypasses ufw
settings.
Strictly speaking, that means unless you are running in Hybrid mode, you do not need the Execution and Consensus client rules.
Adding them, however, has no downside and will make sure that if you ever switch to Hybrid mode you will not run into firewall issues.
(Optional) Enable Brute-Force and DDoS Protection
To protect your server from DDoS attacks and brute-force connection attempts, you can install fail2ban
.
This program will monitor incoming connections and block IP addresses that try to log in with faulty credentials repeatedly.
See this guide for more information on intrusion prevention.
Run the following commands on your node machine:
Install the service:
sudo apt install -y fail2ban
Next, open /etc/fail2ban/jail.d/ssh.local
:
sudo nano /etc/fail2ban/jail.d/ssh.local
Add the following contents to it:
[sshd]
enabled = true
banaction = ufw
port = 22
filter = sshd
logpath = %(sshd_log)s
maxretry = 5
You can change the maxretry
setting, which is the number of attempts it will allow before locking the offending address out.
Once you're done, save and exit with Ctrl+O
and Enter
, then Ctrl+X
.
Finally, restart the service:
sudo systemctl restart fail2ban
And with that, you've just greatly improved the security posture of your node. Congratulations!

================================================================================




- Ava Protocol EigenLayer AVS Explained
- An in-depth explanation
- of the Ava Protocol
- EigenLayer AVS,
- covering its architecture,
- setup,
-  and operational guidelines.
-   The Ava Protocol AVS
-    (Actively Validated Service)
-  can be compiled directly
-  using Go version 1.22+.
-  Ensure you have the appropriate version
-  of Go installed
-  in your development environment.

Does this mean they already have an SDK in Go?
Look up "advice on building an SDK"


- For each owner, an ERC6900 wallet
- is deployed
- to schedule tasks
- and approve spending.
- Each task type
- has its corresponding
- modular code
- to represent its condition
- and actual execution.
- The aggregator accepts
- RPC requests
- from clients
-  to submit task payloads.
-  Currently, the Ava Protocol team
-  manages and runs
-  the aggregator.
-  Periodically, the aggregator combines
-  task submissions,
-   updates internal storage,
-   and writes a zkSNARK proof
-   back to our TaskManager contract.
-   The aggregator
-   also accepts task condition check results
-   from the operator,
-   performs quorum and consensus checks,
-   and flags tasks as ready to run.
-   The Ava Protocol team currently manages
-   the aggregator.
-   Depending on whether you are
-   on the testnet or mainnet,
-   point your operator
-   to the appropriate address
-   in the operator
-   configuration file.
-   AVS node: aggregator-holesky.avaprotocol.org:2206
- API Explorer: https://api-explorer-holesky.avaprotocol.org/
- AVS node: aggregator.avaprotocol.org:2206
- API Explorer: https://api-explorer.avaprotocol.org/
- Operators communicate with aggregators
- via RPC.
- They request task data
- from the aggregator,
- execute condition checks,
- and send results back
- to the aggregator.
- For tasks deemed ready to run,
- operators execute them.
- Detailed information on task execution
- through our ERC6900 modular wallet
- will be available soon.

- a sample for how to make an SDK?
- Check Python Version
- Verify the installed Python version:
- python3 --version ?
- Download and install the AVS Python SDK using the following command:
- pip3 instal / brew install
- You can then run the ap-avs binary.
- We strive to use pure Go,
- allowing cross-compilation
- for any architecture
- supported by the Go compiler.
- Refer to the operator documentation
- for detailed instructions.
- To run the aggregator,
-  use the following command:
-  ap-avs aggregator
-  Note: The Ava Protocol team
-  currently manages the aggregator,
-  and the IP address for communication
-   between the operator and the aggregator
-   is hardcoded in the operator.
-   Operators connected to the Ava Protocol aggregator
-   can monitor their operations
-   on the telemetry dashboard.
Testnet
https://aggregator-holesky.avaprotocol.org/telemetry
Mainnet
https://aggregator.avaprotocol.org/telemetry
Development Guide
Refer to the development documentation.
Dependencies
EigenLayer CLI
Install the EigenLayer CLI with the following command:
curl -sSfL https://raw.githubusercontent.com/layr-labs/eigenlayer-cli/master/scripts/install.sh | sh -s
Golang
Install Go with the following command:
brew install go
Foundry Toolchain
Install the Foundry toolchain with the following commands:
curl -L https://foundry.paradigm.xyz | bash
foundryup
Protobuf Compiler
Install the Protobuf compiler with the following command:
go install google.golang.org/protobuf/cmd/protoc-gen-go@latest
Contract address
Holesky Testnet
Name | Address |
---|---|
ProxyAdmin | 0x26CF7A7DF7d1E00D83A5Ca24385f697a3ca4577d |
ServiceManager | 0xEA3E82F9Ae371A6a372A6DCffB1a9bD17e0608eF |
RegistryCoordinator | 0x90c6d6f2A78d5Ce22AB8631Ddb142C03AC87De7a |
BLSApkRegistry | 0x6752F8BeeE5BF45c9d11FDBC4F8aFfF879925585 |
IndexRegistry | 0x298a5d3C8F8Db30E8292C9e2BF92292de469C8FF |
OperatorStateRetriever | 0xb7bb920538e038DFFEfcB55caBf713652ED2031F |
PauserRegistry | 0x3A8ea6e4202CdDe4a9e0cCE19c4Dc1739ba2cF0b |
StakeRegistry | 0x7BacD5dd5A7C3acf8bf1a3c88fB0D00B68EE626A |
ApConfig | 0xb8abbb082ecaae8d1cd68378cf3b060f6f0e07eb |
Ethereum Mainnet
Name | Address |
---|---|
ProxyAdmin | 0x5989934D31f7f397511f105B7E4175a06B7A517F |
ServiceManager | 0x18343Aa10e3D2F3A861e5649627324aEAD987Adf |
RegistryCoordinator | 0x8DE3Ee0dE880161Aa0CD8Bf9F8F6a7AfEeB9A44B |
BLSApkRegistry | 0xB58687fF303C8e92C28a484342755d3228081d45 |
IndexRegistry | 0xc6A464e39d4fA5013D61295501c7cCd050d76612 |
OperatorStateRetriever | 0xb3af70D5f72C04D1f490ff49e5aB189fA7122713 |
PauserRegistry | 0xeec585186c37c517030ba371deac5c17e728c135 |
StakeRegistry | 0x363b3604fE8c2323a98c00906115c8b87a512a12 |
TaskManager | 0x940f62f75cbbbd723d37c9171dc681dfba653b49 |
ApConfig | 0x9c02dfc92eea988902a98919bf4f035e4aaefced |

================================================================================

Set up EigenLayer Operator
Step-by-step guide to registering as an operator with Ava Protocol AVS and running the operator software using Docker.
This guide will walk you through the process of registering as an operator to Ava OProtocol AVS and running the Ava Protocol software.
This guide focus on running everything with-in docker container. If you don't want to use docker container, you can follow other guide instead
Prerequisite
An operator need to be onboard and setup their own operator with EigenLayer, following the official document
Software/Hardware Requirement
-
Operating System: Linux, MacOS
-
CPU: x64/arm.
-
vCPUs: 1
-
Memory: 1GiB
-
Storage: 100GB
-
EC2 Equivalent: c6gd.medium, m6g.medium, c7a.medium, c6g.large
-
Expected Network Utilization:
- Total download bandwidth usage: 1 Mbps
- Upload bandwidth usage: 1 Mbps
-
Incoming Ports: open firewall for these ports. If you customize the docker compose port then adjust accordingly.
- Mainnet: 9190, 9191.
- Holesky: 9290, 9291.
-
Outgoing Ports: 2206
If your cloud providers support Arm CPU, we suggest to use Arm because it's more cost effective.
Operator Setup
1. Clone this repository
git clone git@github.com:AvaProtocol/ap-operator-setup.git
cd ap-operator-setup
We had two directory call holesky
and ethereum
. To setup testnet, you will do everything inside hokesky
directory. For mainnet deployment, you would use files inside ethereum
directory.
2. Prepare config file and credential
To setup for holesky testnet, we would do everything inside holesky
directory.
To setup for ethereum mainnet, we would do everything inside ethereum
directory.
Inside holesky
or ethereum
directory, We will need to prepare 2 files: .env
and config.yaml
.
-
Make sure you are under
ethereum
orholesky
direction, and prepare.env
filecp .env.example .env
-
Then, edit it and fill in these information:
Specify your operator’s keystore location and password. These are to be used to commit to your registered operator.
- ECDSA_KEYSTORE_PATH= - ECDSA_KEY_PASSWORD= - BLS_KEYSTORE_PATH= - BLS_KEY_PASSWORD=
Besides, the DB_PATH is to specify the local path to store your operator’s data for our AVS.
- DB_PATH=
We don't use high io so you can store on a normal volume such as gp3 with 3000 IOPS on EC2.
If the default ports of PUBLIC_NODEAPI_PORT and PUBLIC_METRICS_PORT were used by different processes, you can also set them to any available ports in your env file too. Make sure to also open firewall to allow traffic incoming to these 2 ports. The default value are:
- Mainnet: 9190 for metric port, 9191 for node api port.
- Holesky: 9290 for metric port, 9291 for node api port.
-
Next, we will create
config.yaml
file for operator:cp config.yaml.example config.yaml
Change the value of
operator_address
to your own operator wallet address.
3. One-time task: Register your operator to Ava Protocol AVS
This step is only needed to be done once per operator. Also, recall that you would need to cd
into holesky
for testnet and ethereum
for mainnet before running anything.
docker compose run ap-operator register --config=/app/config.yaml
To check the registration status at any given time you can also do:
docker compose run ap-operator status --config=/app/config.yaml
Ensure that you successfully register your operator before moving to step 3.
4. Start to run our AVS
At this point, you're ready to run your AVS. Optionally you can consider setting up alias key by following set up alias keys to avoid direct access to EigenLayer ECDSA operator key. You can also switch to the alias key setup at a later time. There is no requirement on following the exact ordering.
-
Make sure you are under
./ethereum
or./holesky
directory. -
Run the following command to start the operator
docker compose pull docker compose up --force-recreate -d
Once the operator is up and running, the output log will look like below.
docker compose up --force-recreate -d [+] Running 1/0 ✔ Container ap_operator Created ✔ Container ap_operator Started
To view the operator log itself, you can do:
docker compose logs -f
The log should appear similar to this:
ap_operator | {"level":"info","ts":1719529804.5644045,"caller":"operator/operator.go:263","msg":"Connect to aggregator aggregator-holesky.avaprotocol.org:2206"} ap_operator | {"level":"info","ts":1719529804.8751178,"caller":"operator/operator.go:307","msg":"Operator info","operatorId":[74,60,26,85,160,147,136,79,102,183,189,62,99,76,192,151,203,7,97,85,230,236,25,160,46,242,83,194,177,93,63,163],"operatorAddr":"0x2273e70Ea0F159985a9312e875839CbF242f162e","operatorG1Pubkey":"E([13980129839750270625587959504067205960106881892608925358182969477593110597180,2713793992502006479543294653290264953732656227600455037615150886215476630684])","operatorG2Pubkey":"E([10006440951214432193970386287330007898372605552301114697229665952718363326438+2917899138783614023915162275072742305856792653861495716209344717215206657922*u,20465317265628248898772842070116958367267377808142334627836040792686631701030+11895853732396257221594908719294998059804388586884333547663795174064486592588*u])"} ap_operator | {"level":"info","ts":1719529805.3309655,"caller":"operator/operator.go:330","msg":"Starting operator."} ap_operator | {"level":"info","ts":1719529805.3310997,"caller":"nodeapi/nodeapi.go:104","msg":"Starting node api server at address 0.0.0.0:9010"} ap_operator | {"level":"info","ts":1719529805.33198,"caller":"metrics/eigenmetrics.go:81","msg":"Starting metrics server at port 0.0.0.0:9090"} ap_operator | {"level":"info","ts":1719529805.3321455,"caller":"nodeapi/nodeapi.go:238","msg":"node api server running","addr":"0.0.0.0:9010"}
Use Watchtower For Auto-update
To perform auto update, we use
watchtower. It watches ap_operator
container and check for the docker image update.
The ap_operator
uses image tag avaprotocol/ap-avs:latest
and not pin to a version. Once a new image is pushed to docker hub and tag with latest
, watchtower detects that a new image has been pushed, it will pull the new avaprotocol/ap-avs:latest
docker image. Then it will recreate the operator container using the new docker image.
Obviously this kind of update will only work when there is no config change required. If there is a configuration change that requires you to set a flag in the config, then we will need to perform a manually config change and then update. However, we try hard to make the update painless and majority of time we can let it auto updated.
To run the auto update simply perform:
# make sure you're inside the `watchtower` directory.
# then bring up docker compose
docker compose up -d
you should see something like this
✔ Container watchtower Started
To check the log you can do:
docker compose logs -f
And it should show up like this:
❯ docker compose logs -f
watchtower | time="2024-07-03T00:01:58Z" level=info msg="Watchtower 1.7.1"
watchtower | time="2024-07-03T00:01:58Z" level=info msg="Using no notifications"
watchtower | time="2024-07-03T00:01:58Z" level=info msg="Only checking containers which name matches \"ap_operator\""
watchtower | time="2024-07-03T00:01:58Z" level=info msg="Scheduling first run: 2024-07-03 08:01:58 +0000 UTC"
watchtower | time="2024-07-03T00:01:58Z" level=info msg="Note that the first check will be performed in 7 hours, 59 minutes, 59 seconds"
You can read more about the watchtower with advanced feature such as Slack notification and build your own docker compose based on our file here.
FAQ
How to update
# pull the lastest change from our repository
git pull
# cd into either mainnet or holesky directory depend on mainne or testnet
cd ethereum
# then issue a pull command to fetch latest image
docker compose pull
# finally restart the container with the new image
docker compose up --force-recreate -d
How to configure auto update
If you want to configure auto update, check our instruction in watchtower
How to check that my operator is working
When your operator connects to aggregator, it will reports telemetry which we can check to ensure your operator is working properly. We're currently working on prometheus metrics and dashboard to provide operator with visibility.
Beside, you will see some log indicate that the operator is working and processing task that our aggregator asked it to do.
You can also visit the telemetry dashboard
Testnet Operator Status Page
https://aggregator-holesky.avaprotocol.org/telemetry

================================================================================

API References
Comprehensive guide to working with gRPC endpoints and API references for the Ava Protocol EigenLayer AVS, including authentication and API methods.
To interact with the Ava Protocol, start by making a request to the gRPC endpoint. The protocol is defined in the protobuf directory. A user can use any protobuf client or SDK to make calls to this gRPC endpoint.
For example, using the Node.js @grpc/grpc-js package, you can make the call as shown in this file: https://github.com/AvaProtocol/EigenLayer-AVS/blob/main/examples/example.js. You can review it to learn how to construct a gRPC client if you're not yet familiar with gRPC.
Endpoint
Ethereum
aggregator-holesky.avaprotocol.org:2206
Holesky
aggregator.avaprotocol.org:2206
Local dev
If you're running the AVS locally using our docker compose in https://github.com/AvaProtocol/EigenLayer-AVS, you can connect to this endpoint
127.0.0.1:2206
Authentication
To start interacting with our protocol for task management, the process consists of two steps:
- Given a wallet address, exchange it for an auth token. This auth token allows you to perform task management for that wallet.
- For any request that requires authentication, include this auth token in request metadata.
auth token
1. Exchange an Call the GetKey
method with the following data:
owner
: your wallet addressexpired_at
: the epoch time when your key will expiresignature
: sign a message in the formatkey request for ${wallet_address} expired at ${expired_at}
The response will include a key that can be set in the metadata of subsequent requests. The token will expire at the expired_at
epoch.
You can refer to this example code for guidance on how to generate the signature.
2. Making a gRPC Request
After obtaining the auth token, for any request that requires authentication, set the authkey: ${your-key-from-above}
header in the request.
Since an account needs to send an auth key generated from the signature above, no one else will be able to view your data, ensuring that your task and parameter data remain private.
API Methods
GetSmartAccountAddress
rpc GetSmartAccountAddress(AddressRequest) returns (AddressResp)
This endpoint retrieves the smart wallet address for a specified owner. No authentication is required because this information can also be gathered from on-chain storage.
Request
- owner (string): The hex address of the account owner whose smart wallet address is being requested.
Response
- smart_account_address (string): The retrieved smart wallet address for the specified owner.
- nonce (string): The current nonce of the smart wallet
CreateTask
rpc CreateTask(CreateTaskReq) returns (CreateTaskResp)
This endpoint is used to create a new task with specific actions and triggers.
Request
- task_type (TaskType): The type of task to create, such as ETHTransferTask or ContractExecutionTask.
- action (TaskAction): The action associated with the task, which can be either an Ethereum transfer (eth_transfer) or a contract execution (contract_execution). The action is complex data structure, refer to [below TaskAction structure] for more document.
- trigger (TaskTrigger): Specifies the conditions under which the task should be executed. Triggers can be based on time, contract query, or an expression. start_at (int64): The epoch time (in seconds) after which the task becomes valid and can be triggered.
- expired_at (int64): The epoch time (in seconds) after which the task is no longer valid and will not be triggered.
- memo (string): An optional field to store arbitrary notes or metadata related to the task.
TaskAction
TaskAction is fundamentally a union type. Depending on task type, the relevant field contains the action data.
-
ETHTransfer: Used when the task is eth transfer
- destination (string): The hex string address of recipient.
- amount (string): the hex string of eth amount.
-
ContractExecution: Used when the task is ContractExecutionTask
- contract_address (string): the target contract address in hex.
- calldata (string): the encoded contract method and its argument to be send to the contract address.
- method (string): optinally - only use for display/format purpose.
- encoded_params (string): optinally - only use for display/format purpose.
TaskTrigger
TaskTrigger is also a union type. Depending on task type, the relevant field contains the trigger data.
-
trigger_type: an enum of TimeCondition, ContractQueryCondition and ExpressionCondition
-
schedule: use when the trigger_type is TimeCondition.
- fixed (array): an list of epoch timestamp when the task can be triggered.
- cron (string): a crontab expression re-present when the task can be triggert
-
contract_query: use when trigger_type is ContractQueryCondition Query a contract, if return value is true, the task is triggered.
- contract_address (string): target contract address in hex format
- callmsg (string): encoded payload in hex format to send to above contract
-
expression: use when trigger_type is ExpressionCondition Perform an expression with operator and function call support by our task engine. If it's evaluated to true, the task is t riggered.
-
expression (string): the raw expression. The language that we use is expr-lang. Beside the built-in primitive support by
expr-lang
, We supported below functions to work with onchain data:- readContractData(contract_address, callmsg): the parameter is similar to contract query with contract_address and callmsg. The queried value is returned.
- latestRoundDataChainlink": chainlinkLatestRoundData
- bigCmp(a, b): compare to Ethereum big int, return 0 if a == b, return 1 if a > b, return -1 if a < b
- toBigint(value): Map to Ethereum ParseBig256
-
Response
- id (string): The unique identifier of the created task.
ListTasks
This endpoint returns a list of tasks associated with the account identified by authkey
Request
No parameters are needed in the request.
Response
- tasks (repeated TaskItemResp): A list of task items associated with the account.
- id (string): The unique identifier of the task.
- status (TaskStatus): The current status of the task, such as Active, Completed, Failed, etc.
CancelTask
rpc CancelTask(string) returns (google.protobuf.BoolValue)
This endpoint is used to cancel the task identified by the given ID. The task will be stopped from running. Only tasks in active status can be canceled.
Request
- id (string) The unique identifier of the task to be deleted.
Response
BoolValue (google.protobuf.BoolValue): Indicates whether the cancellation was successful (true) or not (false).
DeleteTask
rpc DeleteTask(string) returns (google.protobuf.BoolValue)
This endpoint deletes a task associated with the given task id
Request
- id (string) The unique identifier of the task to be deleted.
Response
BoolValue (google.protobuf.BoolValue): Indicates whether the deletion was successful (true) or not (false).
API clients
Using protocol definition in protobuf
anyone can generate a client use traditional grpc tool. Userful link to working with gRPC:
Refer to this example for a demonstration of how to construct the gRPC client and make call.

================================================================================

Ava Protocol AVS Overview
Explains the roles and interaction among EigenLayer AVS and Operators
Overview
The purpose of Ava Protocol AVS is to enable one to setup automation that run based on a condition. The actual action to be performed can be a simpler condition such as transfering ETH or ERC20 token, or executing any contract method. These actions can be formed and chain together to provide condition logic. Besides on-chain transaction, we can also execute off-chain transaction such as making graphql call, or HTTP request.
Smart Wallet
Naturally, to run a transaction, we need a way to generate a signature for that transaction. For security reason, we obviously don't want to keep or manage your private key. Therefore, we leverage the ERC-4337 and ERC-6900 to allow us deploy an account abstraction wallet for you. From now on, we will call it smart wallet. Your automation will run from this wallet. Therefore, when you send fund or perform smart contract call, the msg.sender
is this smart wallet address.
You can transfer assets into this smart wallet to pay for fee and necessary assets that relevant to your transaction. Example, if you're running a swap, you want to keep enough amount of asset in this wallet.
Optionally, we can also withdrawal asset from your EOA too, eliminate the need of depositing assets ahead of time.
You're in full control of this smart wallet, as in you can transfer assets in and withdrawl assets out anytime.
Operators
Operators are stateless node, that perform the task of checking the triggering continously and notify Ava Protocol aggregators when a condition is met.
Aggregator gRPC
Aggregator are the stateful node, that stored your task data. To schedule a new task or perform any task management action on an existing task, an user will talk to this aggregator gRPC endpoint.
Head to api reference to know how to perform these action programmatically.
Currently, there is no UI to manage tasks yet. However, one can use our telegram bot to perform this task. We will soon release this bot to public for use.
Local developemt
Follow https://github.com/AvaProtocol/EigenLayer-AVS/blob/main/docs/development.md to spin up a locally node and run the aggregator locally.
Next steps
Head to api reference Learn how to schedule task with our aggregator gRPC.

================================================================================

Securing with Alias Key
Learn how to secure your EigenLayer operator with an Alias Key, enhancing security by protecting the operator ECDSA key during interactions with Ava Protocol.
The operator ECDSA key allows access to funds under that account. Optionally, you can use a different ECDSA key pair from your EigenLayer operator ECDSA key and bind this new alias key to your operator. This way, your operator can use the new alias key to interact with the Ava Protocol whereas the AP AVS software will not have access to your operator ECDSA key.
The process includes two steps:
- Generate or import an existing ECDSA key to create an alias key.
- Bind the alias key to your operator ECDSA key.
While it's not necessary to perform these steps, doing so enhances security by ensuring that your operator ECDSA key remains protected.
You do need access to the operator ECDSA key to perform below steps.
Pre-requirement
- You have clone https://github.com/AvaProtocol/ap-operator-setup into your hard drive
- You have finished the operator registering to AP AVS.
Generate alias key
We will generate an alias key and temporarily put them in a folder call keys
. You will move them to the right location later.
# create the temp directory to hold the generated keys
mkdir keys
docker compose run -v `pwd`/keys:/app/keys/ ap-operator --config=/app/config.yaml create-alias-key --name=/app/keys/alias-ecdsa.key.json
A file call alias-ecdsa.key.json should be created inside the keys directory. You can move it to the right place on your node. This will be your alias key moving forward.
This key share the same password with your original EigenLayer Operator key.
Declare the alias key for your operator
Now, we will send an on-chain transaction from your operator ECDSA key to bind the newly generated alias key to it.
Ensure your operator ECDSA key has some fund in it to pay for the gas fee.
docker compose run -v path-to-the-alias-ecdsa-key.json-above-on-your-node:/app/keys/alias-ecdsa.key.json ap-operator declare-alias --config=/app/config.yaml --name=/app/keys/alias-ecdsa.key.json
You should see a message like this at the end.
succesfully declared an alias for operator [your-operator-keys] alias address [your-alias-address-key] at tx [tx-hash]
Now, in your .env file, you can replace ECDSA_KEYSTORE_PATH, which is pointed to your operator ECDSA key, to point to the path of the alias key we just create in above step.
ECDSA_KEYSTORE_PATH=<path-to-the-above-alias-ecdsa-key-file-above>
You're all set to move forward with running your operator using this alias key. At any given time, you can also just change the ECDSA_KEYSTORE_PATH to point to your original operator ECDSA key to perform operation that require the operator ECDSA key. Usually, only the registraion and deregistration require that key.
Because the operator run inside a docker container, it can only access what file we mounted into it. And with the above step, your EigenLayer operator key isn't mounted into the container at run time, only the alias key. Therefore, your key are secured and not expose to the AP AVS during life-cycke of the AP AVS Operator container.

================================================================================

FAQ
Explore frequently asked questions about Ava Protocol, covering its features, benefits, integration with DeFi platforms, and more.
Frequently Asked Questions
What is Ava Protocol?
Ava Protocol is an event-driven EigenLayer AVS that enables seamless autonomous transactions for Ethereum and beyond. It empowers developers to improve crypto transactions with intelligent automation, enhanced privacy, effortless composability, and significant cost savings.
How does Ava Protocol help DeFi developers?
Ava Protocol automates key aspects of DeFi development, such as on-chain interest rate updates, liquidity management, and liquidation processes. This reduces the need for manual monitoring, lowers operational costs, and improves platform reliability.
How does Ava Protocol enhance DeFi platforms?
Ava Protocol improves platform reliability by automating functions and optimizing processes. This saves developers time, reducing inefficiencies and allowing them to focus on innovation. Ava Protocol ensures timely updates, precise liquidations, and streamlined operations.
Can Ava Protocol integrate with existing DeFi platforms?
Ava Protocol supports both Ethereum and Polkadot, providing broad compatibility with existing applications and services. Developers can seamlessly integrate automation and advanced transaction functionalities across EVM-compatible and Substrate-based chains.
How does Ava Protocol ensure transaction privacy and security?
Ava Protocol enhances transaction privacy and security through advanced MEV (Maximal Extractable Value) protection mechanisms. This approach prevents external entities from intercepting or manipulating transactions, ensuring that transactions are confidential and shielded from front-running and other malicious activities.
Who can benefit from Ava Protocol?
Ava Protocol's enhanced automation benefits developers, DeFi traders, gaming projects, NFT artists, real-world asset applications, and users of practically any web3 vertical. By empowering seamless automation through super-transactions, Ava Protocol opens up new possibilities and use cases across the web3 ecosystem.
How can I get started with Ava Protocol?
You can start by trying our testnet. Visit Ava Protocol Testnet to begin exploring the features and capabilities of Ava Protocol.
For additional questions or suggestions to improve this documentation, please create a GitHub Issue on our Repository.

================================================================================

